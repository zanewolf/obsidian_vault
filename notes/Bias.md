Bias is unfairly favoring one view over another. There are fair reasons to favor one view over another (e.g. not portraying a racist argument as equally factually sound as the nonracist argument), but unfair bias often originates from unquestioned assumptions (e.g. a doctor assuming that a woman's pain is negligible while a man's pain is not) or from poor methodolgy. There are two [[Systems of thinking]] and design requires the second, slow system, but often the audience will use the first system to do the initial read, and can miss important aspects. 

Sometimes guidelines and systems are in place to protect against bias - such as insisting on specific graphs, style options, organization patterns, etc. that the audience is already familiar with and be able to more easily access and understand. It's important to know how these systems protect against bias and if there's ways to introduce novelty within those systems without incurring bias. 


## Sources of Bias
![[Pasted image 20230504131806.png]]

Our own cognitive biases affect our work: 
- Conservatism Bias: When we are presented with new information, we might insist on sticking to our beliefs instead of revising them
- Confirmation bias: We generally surround ourselves with people who share the same beliefs (and therefore might come to the same conclusions as us)
	- Bandwagon Effect: A lot of people around us share a belief, so it's easier for us to adopt
	- Herd Mentality: following others just because there are many, but not understanding or agreeing with their points
	- Exposure Effect: seeing something frequently might make us favor it more
- Story bias: stories are very powerful
	- Narrative fallacy: information seems more important if it is delivered via a story
	- Framing bias: more inclined to make decisions that make for better stories
	- Both of these highlight the need for System 2 thinking in design, because context is incredibly important
- Identifiable Victim Bias: 
	- "10000 deaths is a statistic, 1 death is a tragedy" 
- Ostrich Effect: ignoring or weighing less information we think is 'negative'
- Omission Bias: understimating the importance of information we have chosen to ignore
- Optimism Bias: Overestimating the odds that good things will happen, and vice versa for negative outcomes
- Fundamental Attribution Error: 
	- we judge our actions based on our intentions but judge others' actions based on consequences
- Information Bias: seeking more information even when it does not affect or encourage action
- Pro-innovation bias: likely to be blinded by new and shiny things - ideas, technologies - and overlooking weaknesses or limitations
- Overconfidence Bias: overestimate ourselves or believe we have more influence than we really do
- Hindsight or Outcome Bias: we may believe a past outcome was inevitable simply because it has already happened, discounting the possibility that it could have been avoided
	- Misinformation effect: our memories are easily colored or altered based on what happened after an events

- Statistical Biases
	- Sampling bias: the sample was not random
		- e.g. voting polls are sampling the people who voted, not everyone eligible to vote
	- Assignment Bias: unfairly grouping subjects post-hoc
	- Correlation Bias: thinking two correlated variables implies causation between the two 
		- Omitted Variable Bias: the variables that appear to be correlated to each other are in fact correlated to an unknown third variable
			- e.g. thinking that stork population and birth rate in a country are correlated to each other when in fact both are correlated to geographic area
	- Observer Bias: outcomes, actions, or behaviors tend to change when a person knows they are being watched
		- Self-reporting Bias: people tend to document things that make them look good, s



### Resources 
 https://medium.com/nightingale/ten-ways-cognitive-biases-impact-data-design-work-be83f86d4274
 [Creative Reaction Lab](https://www.surveymonkey.com/r/ECCDfieldguidedownload).


